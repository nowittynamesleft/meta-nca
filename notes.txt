- Training seems unstable; sometimes 500 meta-epochs gets to 96% val accuracy and sometimes it stays at 33% the whole time
- CPU training is faster (500 metaepochs with visualizations: 91 seconds with GPU, 44 seconds with CPU)
	- no visualization: 46 seconds with CPU (?), 84 seconds with GPU

- Todo:
	- Make it possible to have more than one layer. Very important. (done! although haven't gotten better accuracies with this yet)
	- What can I do to understand the way these things learn? (read stuff about learning dynamics, probably should go back to the "science of dl" slack to see if there's anything there. alternatively, could ask naomi/others from kc lab for recs)
	- How did David Ha "learn" gradient descent with local rules? find this out from paper

Description of model:
This is a meta-learning algorithm that learns local rules of neural network updates through gradient descent.

What do we have?

A local rule neural network. This takes in input of a current weight w, hidden state h_w of that w, the sum of the forward weights w_{f}, and the sum of their hidden states h_{w_{f}}, same for backward weights w_{b} and h_{w_{b}} and outputs the update in the weight \delta_w and the update to the hidden state h_{w}. 



Need to:
- Need to parallelize the local_rule_nn. Activations make everything much slower.
    - Parallelized the local_nn call but haven't yet parallelized the indexing and concatenation. Need to
    do that so things are faster; the for loop is the more time-consuming part.
- simplify nca_local_rule code but make sure it can run on stuff without the activation part
- then trace a gradient through one entire training loop


So now that nca_local_rule code is a bit more simplified (with separate functions), we can begin to
try to include activations. Need to look at that branch that has the code that includes activations.

IDEAS:
- include activations

Does any of the following matter when we don't include activations yet?
- think about taking some (good?) task nns from the previous meta-epoch and continue training them (so that
  we can train good ones further without loss of performance)
    - What about training with only the best ones for the loss?
    - What about training to optimize for difference in loss between epochs, so we get a
      local_rule_nn that reduces loss most times you apply it?
